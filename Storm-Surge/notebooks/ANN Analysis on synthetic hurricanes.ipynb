{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62532, 10)\n",
      "[[ 0.08869374  0.07273774  0.07650217  0.07998341  0.10801552  0.11094129\n",
      "   0.33401603  0.12339592  0.18891034  0.26151556  0.0054      0.0051\n",
      "   0.0056      0.0059      0.0068      0.0071      0.0114      0.0122\n",
      "   0.0134      0.0167    ]\n",
      " [-0.00694975  0.00128717  0.01496709  0.00864799  0.00684242  0.03885008\n",
      "   0.12532118  0.02930014  0.04543016  0.04305997  0.0041      0.0048\n",
      "   0.0056      0.0061      0.0058      0.0071      0.01        0.0108\n",
      "   0.0138      0.0159    ]]\n"
     ]
    }
   ],
   "source": [
    "network_out = np.loadtxt(\"../code/test_track_out.dat\")\n",
    "true_out = np.loadtxt(\"../data/ann_dataset_10points_combined.out\")\n",
    "print(network_out.shape)\n",
    "predicted_vs_actual = np.hstack((network_out, true_out[:,8:]))\n",
    "print(predicted_vs_actual[:2,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(network_out[:2*193,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36239\n",
      "[0.31081665000915526, 0.22333270440101624, 0.019749852007627487, 0.011854489183425909, 0.49102901506423946, 1.4919900444626808, 0.051354314613342278, 0.16495859050750733, 0.031382253324985503, 0.068443360328674319]\n",
      "(62532, 20)\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "k = np.argmax(np.abs(predicted_vs_actual[:,i]-predicted_vs_actual[:,i+10]))\n",
    "print(k)\n",
    "max_error_case = [np.abs(predicted_vs_actual[k,i]-predicted_vs_actual[k,i+10]) for i in range(10)]\n",
    "print(max_error_case)\n",
    "start = 0 #(k // 193)*193\n",
    "stop = 193*20 #start + 193\n",
    "#start = 0\n",
    "#stop = 20*193\n",
    "\n",
    "print(predicted_vs_actual.shape)\n",
    "fig = plt.figure(figsize=(10, 6), dpi=80)\n",
    "for i in range(10):\n",
    "    sp = fig.add_subplot(10,1,i+1)\n",
    "    if i <= 4:\n",
    "        sp.set_ylim([-0.5, 3.0])\n",
    "    else:\n",
    "        sp.set_ylim([-0.5, 3.5])\n",
    "    sp.plot(predicted_vs_actual[start:stop,i],color=\"blue\", linewidth=1.5, linestyle=\"-\", label=\"prediction\")\n",
    "    sp.plot(predicted_vs_actual[start:stop,i+10],color=\"red\", linewidth=1.5, linestyle=\"-\", label=\"observation\")\n",
    "#plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62532,)\n",
      "(1.1237318642940517, -0.0024490862555934271, 0.011467140514013891)\n",
      "(1.1237318642940517, -0.0024490862555934271, 0.011467140514013891)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "\n",
    "diff = (network_out-true_out[:,8:])\n",
    "diff = diff[:,5]\n",
    "print(diff.shape)\n",
    "\n",
    "#stats.probplot(diff, dist=\"norm\", plot=pylab)\n",
    "stats.probplot(diff, dist=\"t\", sparams=(2), plot=pylab)\n",
    "pylab.show()\n",
    "\n",
    "num_bins = 100\n",
    "# the histogram of the errors\n",
    "n, bins, patches = plt.hist(diff, num_bins, normed=1, facecolor='blue', alpha=0.5)\n",
    "\n",
    "params = stats.t.fit(diff)\n",
    "print(params)\n",
    "dist = stats.t(params[0], params[1], params[2])\n",
    "x = np.linspace(-2, 2, num_bins)\n",
    "plt.plot(x, dist.pdf(x), 'r-', lw = 3, alpha=0.5, label='t pdf')\n",
    "plt.show()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test distribution of errors:\n",
    "The best fit (R^2 = 0.855) is Student's T with 1.067 DOF, location 0.003919 (network slightly overestimates), scale = 0.01165\n",
    "However, T overestimates the probability of large errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62532,)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "diff = (network_out-true_out[:,8:])\n",
    "#print(diff.shape)\n",
    "y = diff[:,5]\n",
    "print(y.shape)\n",
    "#y = np.square(y)\n",
    "x = np.arange(-3,3,0.01)\n",
    "size = diff.shape[0]\n",
    "\n",
    "h = plt.hist(y, bins=100,  color='w')\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(0,1000)\n",
    "\n",
    "dist_names = ['t']\n",
    "\n",
    "for dist_name in dist_names:\n",
    "    dist = getattr(scipy.stats, dist_name)\n",
    "    param = dist.fit(y)\n",
    "    #param = (1.5, param[1], param[2])\n",
    "    pdf_fitted = dist.pdf(x, *param[:-2], loc=param[-2], scale=param[-1])*2000\n",
    "    plt.plot(x, pdf_fitted, label=dist_name)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1237318642940517, -0.0024490862555934271, 0.011467140514013891)\n",
      "1.12373186429\n",
      "-0.00244908625559\n",
      "0.011467140514\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "stats.probplot(y, dist=\"t\", sparams=(2), plot=pylab)\n",
    "pylab.show()\n",
    "\n",
    "print(param)\n",
    "print(*param[:-2])\n",
    "print(param[-2])\n",
    "print(param[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempts to fit nonparametric distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62532,)\n",
      "Probability of the error between -0.10 and 0.10 meters: 0.9672\n"
     ]
    }
   ],
   "source": [
    "# Gaussian kernel density estimation\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = diff[:,4]\n",
    "print(y.shape)\n",
    "kde1 = stats.gaussian_kde(y)\n",
    "#kde2 = stats.gaussian_kde(y, bw_method='silverman')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "#ax.plot(y, np.zeros(y.shape), 'b+', ms=20)  # rug plot\n",
    "x_eval = np.linspace(-2, 2, num=200)\n",
    "#ax.plot(x_eval, kde1(x_eval), 'k-', label=\"Scott's Rule\")\n",
    "#ax.plot(x_eval, kde2(x_eval), 'r-', label=\"Silverman's Rule\")\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.show()\n",
    "\n",
    "err_min, err_max = -0.1,0.1\n",
    "\n",
    "print(\"Probability of the error between %.2f and %.2f meters: %.4f\"%(err_min, err_max,kde1.integrate_box_1d(err_min, err_max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -1.1435m, Max: 0.4936m\n",
      "Probability of the error between -0.13 and 0.13 meters: 0.9519\n"
     ]
    }
   ],
   "source": [
    "### Gaussian kernel density estimation for \"active\" portions of the data only\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "active_start = 130\n",
    "active_stop = 160\n",
    "y = diff[:,0]\n",
    "\n",
    "active_y = y.reshape(-1,193).transpose()[active_start:active_stop,:].reshape(-1)\n",
    "\n",
    "print(\"Min: %.4fm, Max: %.4fm\" %(np.amin(active_y),np.amax(active_y)))\n",
    "kde1 = stats.gaussian_kde(active_y)\n",
    "kde2 = stats.gaussian_kde(y, bw_method='silverman')\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111)\n",
    "\n",
    "#ax.plot(active_y, np.zeros(active_y.shape), 'b+', ms=20)  # rug plot\n",
    "x_eval = np.linspace(-2, 2, num=200)\n",
    "#ax.plot(x_eval, kde1(x_eval), 'k-', label=\"Scott's Rule\")\n",
    "#ax.plot(x_eval, kde2(x_eval), 'r-', label=\"Silverman's Rule\")\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.show()\n",
    "\n",
    "err_min, err_max = -0.13,0.13\n",
    "\n",
    "print(\"Probability of the error between %.2f and %.2f meters: %.4f\"%(err_min, err_max,kde1.integrate_box_1d(err_min, err_max)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
